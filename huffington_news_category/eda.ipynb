{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "# python -m spacy download en\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from keras import models, layers\n",
    "# from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../boto-config.json') as json_data:\n",
    "    boto_config = json.load(json_data)\n",
    "    \n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=boto_config['aws_access_key_id'],\n",
    "    aws_secret_access_key=boto_config['aws_secret_access_key']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "src_file = data_dir + '/News_Category_Dataset.json'\n",
    "src_file_cleaned = data_dir + '/News_Clean.csv'\n",
    "\n",
    "# s3.upload_file(src_file, boto_config['buckets']['kaggle'], src_file)\n",
    "# s3.upload_file(src_file_cleaned, boto_config['buckets']['kaggle'], src_file_cleaned)\n",
    "\n",
    "# s3.download_file(boto_config['buckets']['kaggle'], src_file, src_file)\n",
    "# s3.download_file(boto_config['buckets']['kaggle'], src_file_cleaned, src_file_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json(src_file, lines=True)\n",
    "df = pd.read_csv(src_file_cleaned)\n",
    "df = df[~df.clean_text.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up text\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "data['text'] = data['headline'] + ' ' + data['short_description']\n",
    "\n",
    "docs = data['text'].tolist()\n",
    "\n",
    "def token_filter(token):\n",
    "    return not (token.is_punct | token.is_space | token.is_stop | len(token.text) <= 3)\n",
    "\n",
    "filtered_tokens = []\n",
    "for doc in nlp.pipe(docs):\n",
    "    tokens = [token.lemma_ for token in doc if token_filter(token) and token.text not in STOP_WORDS]\n",
    "    filtered_tokens.append(' '.join(tokens))\n",
    "\n",
    "data['clean_text'] = filtered_tokens\n",
    "\n",
    "data.to_csv(src_file_cleaned, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf with sklearn\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "bag = tfidf.fit_transform(df.loc[:, 'clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbler = LabelEncoder()\n",
    "labels = to_categorical(lbler.fit_transform(df['category']))\n",
    "num_labels = labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tfidf.transform(df.loc[:, 'clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size = 0.2, random_state = 1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn with keras\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 10, batch_size=256, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfpy36]",
   "language": "python",
   "name": "conda-env-tfpy36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
